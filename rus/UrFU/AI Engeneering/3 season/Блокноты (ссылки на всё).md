
# Поиск аномалий

Блокнот Google Colab с рассмотрением библиотеки sklearn для поиска аномалий на синтетических данных <br />
https://colab.research.google.com/drive/1IHeF2SOlZPMs7itL3FETrco4uuy5xxGC?usp=sharing <br />

Рассмотрены: <br />
- Базированный EllipticEnvelope (опять крутим Эллипсы / Эллипсоиды)
- OneClassSVM (опять крутить ядра)
- метрический подход LocalOutlierFactor (а также тонкости в задаче поиска новизны и выбросов) 
- Случайные проекции IsolationForest 
- Метод DecisionBoundaryDisplay для визуализации принятия решений моделями

# Про Вложения (Embedding)

**Image_Embedding_Tensorflow** <br />
https://colab.research.google.com/drive/19BmmDiCckwIuAutBA0FiierrJNOfE3nW?usp=sharing <br />
- Предварительн обученные модели в **TensorFlow**
- Слой *KerasLayer* (чтобы именно вложения генерировал)
- скачиваем данные по ссылке и складываем в *Dataset* от **tensorflow**
- получаем вложения, в зависимости от модельки. Каеф
- возможо для каждой модельки нужно настраивать свою предварительную обработку 

**NLP_Embedding_Hugging_Face** <br />
https://colab.research.google.com/drive/11Ow9juvCr3-iKizRGQ9BYVVe8WzRi9Kd?usp=sharing <br />
- установка библиотеки **datasets**
- загружаем модель и токенизатор из **transformers** (почему-то вариант DeepPavlov)
- грузим набор данных из Kaggle
- подготовительные функции чтобы проще извлекать вложения


# Про Объяснения

## Табличные данные

**XAI на наборе данных Cars Moldova. Регрессия. База от scikit-learn** <br />
https://colab.research.google.com/drive/1O6ArM-499DJi0ZNe6LCkYWpgcByw2JU_?usp=sharing <br />
- Вспоминаем про *pipeline* и обработку признаков с помошью *StandardScaler* , *OneHotEncoder* и *TargetEncoder* для *SGDRegressor*, а также Предобразование целевой переменной с помощью класса *TransformedTargetRegressor*
- Анализ весов линейной регрессии
- Для анализа ошибок модели используем *PredictionErrorDisplay*
- Бустинг *CatBoost* и анализ значимых признаков и деревьев внутри
- Для более перспективной оценки значимости признаков используем *permutation_importance*
- Для анализа вклада отдельнго признака используем *PartialDependenceDisplay*
- В основном глобальная интерпретируемость

**XAI на наборе данных Cars Moldova. Регрессия. Shap** <br />
https://colab.research.google.com/drive/1OB827rJL5GuGwIKjKvZDmf9BzeV4lfST?usp=sharing <br />
- установка библиотеки **shap**
- *Explainer* и  *TreeExplainer* в зависимости от того, какая модель на входе
- разные графики *summary_plot*, *force*, *waterfall*, *heatmap*, *scatter*
- глобальная и локальная интерпретируемость 

**XAI. Изображения. MNIST. Shap** <br />
https://colab.research.google.com/drive/1pxy-WeCIorVI5OeepK298kYevWkGh-kP?usp=sharing <br />
- установка библиотеки **shap**
- качаем *MNIST*, применяем **PCA** и классифицируем это всё безобразие **RandomForestClassifier**
- разные графики *summary_plot*, *force*, *waterfall*, *heatmap*, *scatter*
- в контексте *классификации*
- глобальная и локальная интерпретируемость 

**XAI на наборе данных Cars Moldova. Регрессия. Lime** <br />
https://colab.research.google.com/drive/10TKWebsA7ac1wbTvYNLA4yIERvcPexeW?usp=sharing<br />
- установка библиотеки **lime**
- *LimeTabularExplainer* 
- визуализация *explain_instance*
- пример как "вручную" подружить *CatBoost* и *lime*
- локальная интерпретируемость 

## Изображения 
**XAI. Нейронки. Изображения. Shap** <br />
https://colab.research.google.com/drive/1oPqqAOSVZrzLyILDdEHDLQu_thqwIOaU?usp=sharing <br />
- установка библиотеки **shap**
- качаем готовую модель от **tensorflow** (почему-то *ResNet50*)
- скачиваем данные по ссылке и складываем в *Dataset* от **tensorflow**
- подготовительные функции чтобы в **shap** запустилось нормально *Explainer*
- отрисовка *image_plot*
- локальная интерпретируемость 

lime

## Текст
**XAI. Трансформеры. Текст. Shap** <br />
https://colab.research.google.com/drive/1P1BxyrHxJC9eh7lJRGqMacmXXm7cGmTL?usp=sharing <br />
- установка библиотек **shap**, **datasets**, **transformers**
- качаем набор текстов из **datasets** 
- загружаем модель и токенизатор из **transformers** (почему-то вариант BERT)
- подготовительные функции чтобы в **shap** запустилось нормально *Explainer*
- график *text* (интерактивное)
- локальная интерпретируемость 

lime


# Про Генеративные модели

## Про перенос стиля
**Простенький пример переноса стилей от TensorFlow**<br />
https://colab.research.google.com/drive/1olZT_bAJAxa4-0eGXXnGq1kch_DeuKCS?usp=sharing<br />
- загрузка из хаба моделей

## Про AutoEncoders
**Простенький пример (полносвязные сети, а не свёртки) автокодировщиков на TensorFlow**<br />
https://colab.research.google.com/drive/1muE2Tm-DbCEpLnw2Rxiu-FadTEDnmsZp?usp=sharing <br />
- создаём свою (со своей хитрой структурой) нейронку как класс 
- что-то про то как делать раннюю остановку, делать чекпоинты модели (в общем интерфейс callbacks)
- как взять что-то из центра модели, и что-то из конца
- генерируем цифру размером 28x28 используя автокодировщик и 4 каких-то числа
- автокодировщики для поиска аномалий

## Про Stable Diffusion 

**Крепкий обзор Stable Diffusion**<br />
https://colab.research.google.com/drive/18R1h0A_1WpHPFHh_V1YzwT1Yuy00Cwiy?usp=sharing <br /> 
Тонкости API для Stabble Diffusion
- повторяемость
- латентные пространства
- Пикачу 

**Генерация изображений Img2Img**<br />
https://colab.research.google.com/drive/1enyAeGJ5IP8nZSn9hdpMi52TPH9IsEDz?usp=sharing<br />
- Рисуем на базе наброска, или заменяем что-то по маске (Inpaint)<br />
- Так же небольшая демонстрация Gradio для "интерфейса из ничего"<br /> 


**Рисуем изображения по контурам другого**<br />
https://colab.research.google.com/drive/1B_xAsdqzwkfZMNrs_r3jbbwiNaxv4BPO?usp=sharing<br />
- Знакомство с ControlNet<br />
- Рисуем по границам (контурам)


**Генерируем изображения используя позы другого**<br />
https://colab.research.google.com/drive/1_sh1_Vi9CHfhEIK2kOx0Z0OfN5hHxJAa?usp=sharing<br />
- Опять ControlNet<br />
- Позы (и для этого есть нейронка)